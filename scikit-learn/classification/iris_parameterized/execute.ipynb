{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.7/site-packages (0.1.20)\n",
      "Requirement already satisfied: boto3>=1.12.8 in /opt/conda/lib/python3.7/site-packages (from sagemaker-experiments) (1.14.17)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.17 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.12.8->sagemaker-experiments) (1.17.17)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.12.8->sagemaker-experiments) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.12.8->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.17->boto3>=1.12.8->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.17->boto3>=1.12.8->sagemaker-experiments) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.17->boto3>=1.12.8->sagemaker-experiments) (1.25.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.17->boto3>=1.12.8->sagemaker-experiments) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "session = sagemaker.Session()\n",
    "sm = boto3.Session().client('sagemaker')\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sepal length  sepal width  petal length  petal width  class\n",
       "0           0           5.1          3.5           1.4          0.2    0.0\n",
       "1           1           4.9          3.0           1.4          0.2    0.0\n",
       "2           2           4.7          3.2           1.3          0.2    0.0\n",
       "3           3           4.6          3.1           1.5          0.2    0.0\n",
       "4           4           5.0          3.6           1.4          0.2    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE = 99\n",
    "\n",
    "DATA_FILE = './aws_sagemaker/scikit-learn/classification/iris_parameterized/data/iris.csv'\n",
    "\n",
    "# load csv in memory\n",
    "data = pd.read_csv(DATA_FILE)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  sepal length  sepal width  petal length  petal width\n",
       "5            5           5.4          3.9           1.7          0.4\n",
       "12          12           4.8          3.0           1.4          0.1\n",
       "17          17           5.1          3.5           1.4          0.3\n",
       "19          19           5.1          3.8           1.5          0.3\n",
       "20          20           5.4          3.4           1.7          0.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into test and training\n",
    "train_data = data.sample(frac=0.8, random_state=RANDOM_STATE)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "test_data = test_data.drop(['class'],axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put train data into csv\n",
    "TRAIN_DATA_FILE = './aws_sagemaker/scikit-learn/classification/iris_parameterized/data/train_data.csv'\n",
    "train_data.to_csv(TRAIN_DATA_FILE, index=False, header=True)\n",
    "\n",
    "# put test data into csv\n",
    "TEST_DATA_FILE = './aws_sagemaker/scikit-learn/classification/iris_parameterized/data/test_data.csv'\n",
    "test_data.to_csv(TEST_DATA_FILE, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push data to S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define S3 Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment metadata would be published at - s3://snowflake-getting-started/iris/experiments\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = 'snowflake-getting-started'\n",
    "BASE_PREFIX = 'iris'\n",
    "\n",
    "INPUT_DATA_PREFIX = BASE_PREFIX+'/data/input'\n",
    "TRAIN_DATA_PREFIX = BASE_PREFIX+'/data/input/train'\n",
    "TEST_DATA_PREFIX = BASE_PREFIX+'/data/input/test'\n",
    "\n",
    "EXPERIMENTS_OUTPUT_LOC = 's3://'+BUCKET_NAME+'/'+BASE_PREFIX+'/experiments'\n",
    "#DEBUGGING_OUTPUT_LOC = 's3://'+BUCKET_NAME+'/'+BASE_PREFIX+'/output/debugging'\n",
    "#MODELS_OUTPUT_LOC = 's3://'+BUCKET_NAME+'/output/models'\n",
    "\n",
    "print ('Experiment metadata would be published at -',EXPERIMENTS_OUTPUT_LOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading train data to s3\n",
      "Input data uploaded to - s3://snowflake-getting-started/iris/data/input/iris.csv\n"
     ]
    }
   ],
   "source": [
    "print ('Uploading train data to s3')\n",
    "\n",
    "s3_input_data_path = session.upload_data(path=DATA_FILE, \n",
    "                           bucket=BUCKET_NAME, \n",
    "                           key_prefix=INPUT_DATA_PREFIX)\n",
    "\n",
    "print ('Input data uploaded to -', s3_input_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Setup an Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment debugging data available at - s3://snowflake-getting-started/iris/experiments/experiment-iris-classification-model-1595847474/debugging\n",
      "Experiment trained moddels available at - s3://snowflake-getting-started/iris/experiments/experiment-iris-classification-model-1595847474/trained_models\n",
      "Experiment source code available at - s3://snowflake-getting-started/iris/experiments/experiment-iris-classification-model-1595847474/code\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "import time\n",
    "\n",
    "EXPERIMENT_NAME=f\"experiment-iris-classification-model-{int(time.time())}\"\n",
    "\n",
    "iris_experiment = Experiment.create(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    description=\"Classification of iris flowers\", \n",
    "    sagemaker_boto_client=sm)\n",
    "\n",
    "EXP_DEBUGGING_OUTPUTS=EXPERIMENTS_OUTPUT_LOC+'/'+EXPERIMENT_NAME+'/debugging'\n",
    "EXP_TRAINED_MODELS=EXPERIMENTS_OUTPUT_LOC+'/'+EXPERIMENT_NAME+'/trained_models'\n",
    "EXP_SOURCE_CODE=EXPERIMENTS_OUTPUT_LOC+'/'+EXPERIMENT_NAME+'/code'\n",
    "\n",
    "print ('Experiment debugging data available at -',EXP_DEBUGGING_OUTPUTS)\n",
    "print ('Experiment trained moddels available at -',EXP_TRAINED_MODELS)\n",
    "print ('Experiment source code available at -', EXP_SOURCE_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing tasks\n",
    "\n",
    "    This is where we would do data pre-processing and convert intput data into some features. These features would then be uploaded to S3 and would be\n",
    "    used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Tracker for Pre-Processing\n",
    "\n",
    "    Here we are doing two things:\n",
    "    1. We are creating a trial-component for 'preprocessing'\n",
    "    2. We are creating a tracker to how it tracks the trial-component. This includes:-\n",
    "        2.1 the artefacts generated for this trial component - for e.g. the S3 location where the artefacts would be stored\n",
    "        2.2 Input data location (S3)\n",
    "        2.3 Output data / Features Location (S3)\n",
    "        2.4 Significant parameters from pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing trial metadata would be stored at - iris/experiment-iris-classification-model-1595847474/metadata/Data-Preprocessing\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "preprocessing_trial_component_name = 'Data-Preprocessing'\n",
    "preprocessing_trial_metadata_prefix = BASE_PREFIX+'/'+EXPERIMENT_NAME+'/metadata'+'/'+preprocessing_trial_component_name        \n",
    "\n",
    "with Tracker.create(display_name=preprocessing_trial_component_name, \n",
    "                    sagemaker_boto_client=sm,\n",
    "                    artifact_bucket=BUCKET_NAME,\n",
    "                    artifact_prefix=preprocessing_trial_metadata_prefix) as tracker:\n",
    "    tracker.log_parameters({\n",
    "         #Record a single parameter value for this trial component.\n",
    "        \"pre_processing_param\": 'pre_processing_param_value'\n",
    "    })\n",
    "    # Record a single input artifact for this trial component.\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"iris-dataset\", media_type=\"s3/uri\", value=s3_input_data_path)\n",
    "    tracker.log_output(name=\"iris-dataset\", media_type=\"s3/uri\", value=s3_input_data_path)\n",
    "    \n",
    "# we are taking the trial component which was created earlir for preprocessing. since for different training trails\n",
    "# our pre-processing trial is the same hence we just attach that preprocessing component to this trial.\n",
    "preprocessing_trial_component = tracker.trial_component\n",
    "    \n",
    "print ('Preprocessing trial metadata would be stored at -',preprocessing_trial_metadata_prefix)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Track Experiment\n",
    "\n",
    "    We next iterate through a loop to run different trials with the hyper parameters. For each iteration we do the following:\n",
    "    1. Create a Trial, since each iteration represents a trial we are doing.\n",
    "    2. Add the pre-processing trial component to this trial\n",
    "    3. Specify a Trial Component for the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "INFO:sagemaker:Creating training-job with name: training-job-iris-classification-model-1595848541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial metadata would be stored at - iris/experiment-iris-classification-model-1595847474/metadatatrial-iris-classification-model-5-max-iter-1595848541\n",
      "2020-07-27 11:15:41 Starting - Starting the training job...\n",
      "2020-07-27 11:15:44 Starting - Launching requested ML instances.........\n",
      "2020-07-27 11:17:20 Starting - Preparing the instances for training......\n",
      "2020-07-27 11:18:23 Downloading - Downloading input data...\n",
      "2020-07-27 11:19:10 Training - Training image download completed. Training in progress..\u001b[34m2020-07-27 11:19:10,843 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-07-27 11:19:10,846 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-27 11:19:10,856 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-07-27 11:19:11,134 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-07-27 11:19:11,134 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-07-27 11:19:11,134 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-07-27 11:19:11,135 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=5955 sha256=6b871479d288705ba6d8fdd2dcb2ef78d3770e6d6a7a9793f869085582c86598\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kt0jzyzu/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34m2020-07-27 11:19:12,534 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-27 11:19:12,545 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"class_weight\": \"balanced\",\n",
      "        \"max_iter\": 5\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"training-job-iris-classification-model-1595848541\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://snowflake-getting-started/iris/experiments/experiment-iris-classification-model-1595847474/code/training-job-iris-classification-model-1595848541/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"class_weight\":\"balanced\",\"max_iter\":5}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://snowflake-getting-started/iris/experiments/experiment-iris-classification-model-1595847474/code/training-job-iris-classification-model-1595848541/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"class_weight\":\"balanced\",\"max_iter\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"training-job-iris-classification-model-1595848541\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://snowflake-getting-started/iris/experiments/experiment-iris-classification-model-1595847474/code/training-job-iris-classification-model-1595848541/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--class_weight\",\"balanced\",\"--max_iter\",\"5\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_CLASS_WEIGHT=balanced\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_ITER=5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train --class_weight balanced --max_iter 5\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34m----> started model training\u001b[0m\n",
      "\u001b[34m---------------> Passed location for data is -> /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m---------------> Files at this location are -> ['iris.csv']\u001b[0m\n",
      "\u001b[34m---------------> Reading data from -> /opt/ml/input/data/training/iris.csv\u001b[0m\n",
      "\u001b[34m---------------> Starting to fit model\u001b[0m\n",
      "\u001b[34m#011---------------> Max Iteration =  5\u001b[0m\n",
      "\u001b[34m#011---------------> Class Weigth =  balanced\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\u001b[0m\n",
      "\u001b[34m---------------> Starting to predict on test data\u001b[0m\n",
      "\u001b[34mTest Accuracy: 0.9473684210526315\u001b[0m\n",
      "\u001b[34mTest F1-Score: 0.9473684210526315\u001b[0m\n",
      "\u001b[34m----> ended model training\u001b[0m\n",
      "\u001b[34m#011----> started model dump\u001b[0m\n",
      "\u001b[34m#011----> ended model dump\u001b[0m\n",
      "\u001b[34m2020-07-27 11:19:13,919 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-07-27 11:19:23 Uploading - Uploading generated training model\n",
      "2020-07-27 11:19:23 Completed - Training job completed\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "from smexperiments.trial import Trial\n",
    "from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig, CollectionConfig\n",
    "\n",
    "save_interval ='1'\n",
    "\n",
    "for i, num_max_iter in enumerate([5]):\n",
    "    \n",
    "    # create trial\n",
    "    trial_name = f\"trial-iris-classification-model-{num_max_iter}-max-iter-{int(time.time())}\"\n",
    "    trial_metadata_prefix = BASE_PREFIX+'/'+EXPERIMENT_NAME+'/metadata'+trial_name\n",
    "    print ('Trial metadata would be stored at -',trial_metadata_prefix)\n",
    "    \n",
    "    iris_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "        experiment_name=iris_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "    )\n",
    "    \n",
    "    # associate the proprocessing trial component with the current trial\n",
    "    iris_trial.add_trial_component(preprocessing_trial_component)\n",
    "    \n",
    "    executor = SKLearn(entry_point='./aws_sagemaker/scikit-learn/classification/iris_parameterized/train.py',\n",
    "                      train_instance_type='ml.c4.xlarge',\n",
    "                      sagemaker_session = session,\n",
    "                      role = role,\n",
    "                      code_location  = EXP_SOURCE_CODE,\n",
    "                      hyperparameters = {\n",
    "                          'max_iter':num_max_iter,\n",
    "                          'class_weight':'balanced'\n",
    "                      },\n",
    "                      input_mode='File',\n",
    "                      metric_definitions=[\n",
    "                        {'Name':'test:f1-score', 'Regex':'Test F1-Score: (.*)'},\n",
    "                        {'Name':'test:accuracy', 'Regex':'Test Accuracy: (.*)'}\n",
    "                      ],\n",
    "                      enable_sagemaker_metrics=True,\n",
    "                      debugger_hook_config=DebuggerHookConfig(\n",
    "                                  s3_output_path=EXP_DEBUGGING_OUTPUTS, \n",
    "                                  hook_parameters={\n",
    "                                    'save_interval': '10'\n",
    "                                  },\n",
    "                                  # Required - See https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md#built-in-collections for supported collections\n",
    "                                  collection_configs=[ \n",
    "                                      CollectionConfig( name=\"default\", \n",
    "                                                        parameters={\n",
    "                                                            'include_regex': 'Test F1-Score: (.*)',\n",
    "                                                            'include_regex': 'Test Accuracy: (.*)'\n",
    "                                                        } \n",
    "                                                      ), \n",
    "                                      #CollectionConfig( name=\"feature_importance\", parameters={ \"save_interval\": save_interval } ), \n",
    "                                  ]\n",
    "                                ),\n",
    "                      output_path = EXP_TRAINED_MODELS\n",
    "                )\n",
    "    \n",
    "    trial_component_training_job = \"training-job-iris-classification-model-{}\".format(int(time.time()))\n",
    "    executor.fit(\n",
    "        inputs={'training': s3_input_data_path},\n",
    "        job_name=trial_component_training_job,\n",
    "        experiment_config={\n",
    "            \"TrialName\": iris_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Model-Training\",\n",
    "        },\n",
    "        logs=True,\n",
    "        wait=True\n",
    "    )\n",
    "    \n",
    "    # give it a while before dispatching the next training job\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training-job-iris-classification-model-1595847478\n"
     ]
    },
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nMissing required parameter in input: \"from\"\nMissing required parameter in input: \"to\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6106a4019de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0mlogGroupName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/aws/sagemaker/TrainingJobs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m      \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sagemaker-getting-started'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m      \u001b[0mdestinationPrefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iris'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    606\u001b[0m         }\n\u001b[1;32m    607\u001b[0m         request_dict = self._convert_to_request_dict(\n\u001b[0;32m--> 608\u001b[0;31m             api_params, operation_model, context=request_context)\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mservice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyphenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_convert_to_request_dict\u001b[0;34m(self, api_params, operation_model, context)\u001b[0m\n\u001b[1;32m    654\u001b[0m             api_params, operation_model, context)\n\u001b[1;32m    655\u001b[0m         request_dict = self._serializer.serialize_to_request(\n\u001b[0;32m--> 656\u001b[0;31m             api_params, operation_model)\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_host_prefix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mrequest_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'host_prefix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/validate.py\u001b[0m in \u001b[0;36mserialize_to_request\u001b[0;34m(self, parameters, operation_model)\u001b[0m\n\u001b[1;32m    295\u001b[0m                                                     operation_model.input_shape)\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mParamValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         return self._serializer.serialize_to_request(parameters,\n\u001b[1;32m    299\u001b[0m                                                      operation_model)\n",
      "\u001b[0;31mParamValidationError\u001b[0m: Parameter validation failed:\nMissing required parameter in input: \"from\"\nMissing required parameter in input: \"to\""
     ]
    }
   ],
   "source": [
    "training_job_desc = executor.jobs[-1].describe()\n",
    "print (training_job_desc['TrainingJobName'])\n",
    "\n",
    "client = boto3.client('logs')\n",
    "client.create_export_task(\n",
    "     logGroupName='/aws/sagemaker/TrainingJobs',\n",
    "     destination='sagemaker-getting-started',\n",
    "     destinationPrefix='iris'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.debugger_hook_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the model training runs for an experiment\n",
    "\n",
    "Now we will use the analytics capabilities of Python SDK to query and compare the training runs for identifying the best model produced by our experiment. You can retrieve trial components by using a search expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Simple Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\":[\n",
    "        {\n",
    "            \"Name\": \"TrialComponentName\",\n",
    "            \"Operator\": \"Contains\",\n",
    "            \"Value\": \"iris\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.session import Session\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(boto3.Session(), sm), \n",
    "    experiment_name=iris_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.test:f1-score.max\",\n",
    "    metric_names=['test:f1-score'],\n",
    "    sort_order=\"Descending\",    \n",
    "    #metric_names=['test:f1-score'],\n",
    "    parameter_names=['max_iter', 'class_weight']\n",
    ")\n",
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(boto3.Session(), sm), \n",
    "    search_expression={\n",
    "        \"Filters\":[{\n",
    "            \"Name\": \"Parents.TrialName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": 'iris-training-job-20-max-iter-1595707533'\n",
    "        },\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }]\n",
    "    },\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Ascending\",\n",
    ")\n",
    "\n",
    "lineage_table.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Debugging Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smdebug\n",
    "from smdebug.trials import create_trial\n",
    "\n",
    "trial = create_trial(EXP_DEBUGGING_OUTPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "def get_data(trial, tname):\n",
    "    \"\"\"\n",
    "    For the given tensor name, walks though all the iterations\n",
    "    for which you have data and fetches the values.\n",
    "    Returns the set of steps and the values.\n",
    "    \"\"\"\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps()\n",
    "    vals = [tensor.value(s) for s in steps]\n",
    "    return steps, vals\n",
    "\n",
    "def plot_collection(trial, collection_name, regex='.*', figsize=(8, 6)):\n",
    "    \"\"\"\n",
    "    Takes a `trial` and a collection name, and \n",
    "    plots all tensors that match the given regex.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.despine()\n",
    "\n",
    "    tensors = trial.collection(collection_name).tensor_names\n",
    "\n",
    "    for tensor_name in sorted(tensors):\n",
    "        if re.match(regex, tensor_name):\n",
    "            steps, data = get_data(trial, tensor_name)\n",
    "            ax.plot(steps, data, label=tensor_name)\n",
    "\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_collection(trial, \"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(trial, importance_type=\"weight\"):\n",
    "    SUPPORTED_IMPORTANCE_TYPES = [\"weight\", \"gain\", \"cover\", \"total_gain\", \"total_cover\"]\n",
    "    if importance_type not in SUPPORTED_IMPORTANCE_TYPES:\n",
    "        raise ValueError(f\"{importance_type} is not one of the supported importance types.\")\n",
    "    plot_collection(\n",
    "        trial,\n",
    "        \"feature_importance\",\n",
    "        regex=f\"feature_importance/{importance_type}/.*\")\n",
    "    \n",
    " plot_feature_importance(trial)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - Real Time Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy Model to an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = executor.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "print('\\nModel Deployed!')\n",
    "\n",
    "print (predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realtime Inference\n",
    "\n",
    "    Lookup the predictor via the endpoint name & call predict on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(DATA_FILE,engine='python')\n",
    "X = data.iloc[:,1:5]\n",
    "y = data.iloc[:,5]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y)\n",
    "pred_y = predictor.predict(test_x)\n",
    "print (pred_y)\n",
    "print (test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
