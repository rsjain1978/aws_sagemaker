{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker-experiments\n",
      "  Downloading sagemaker_experiments-0.1.20-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: boto3>=1.12.8 in /opt/conda/lib/python3.7/site-packages (from sagemaker-experiments) (1.14.17)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.12.8->sagemaker-experiments) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.17 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.12.8->sagemaker-experiments) (1.17.17)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.12.8->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.17->boto3>=1.12.8->sagemaker-experiments) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.17->boto3>=1.12.8->sagemaker-experiments) (1.25.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.17->boto3>=1.12.8->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.17->boto3>=1.12.8->sagemaker-experiments) (1.14.0)\n",
      "Installing collected packages: sagemaker-experiments\n",
      "Successfully installed sagemaker-experiments-0.1.20\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "session = sagemaker.Session()\n",
    "sm = boto3.Session().client('sagemaker')\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sagemaker-user/aws_sagemaker/scikit-learn/classification/iris_parameterized'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-334933e8c008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/sagemaker-user/aws_sagemaker/scikit-learn/classification/iris_parameterized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sagemaker-user/aws_sagemaker/scikit-learn/classification/iris_parameterized'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/home/sagemaker-user/aws_sagemaker/scikit-learn/classification/iris_parameterized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./data/iris.csv does not exist: './data/iris.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-781c9eb3ace9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load csv in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ./data/iris.csv does not exist: './data/iris.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE = 99\n",
    "\n",
    "DATA_FILE = './data/iris.csv'\n",
    "\n",
    "# load csv in memory\n",
    "data = pd.read_csv(DATA_FILE)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3a88442c6b09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# split data into test and training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# split data into test and training\n",
    "train_data = data.sample(frac=0.8, random_state=RANDOM_STATE)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "test_data = test_data.drop(['class'],axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put train data into csv\n",
    "TRAIN_DATA_FILE = './data/train_data.csv'\n",
    "train_data.to_csv(TRAIN_DATA_FILE, index=False, header=True)\n",
    "\n",
    "# put test data into csv\n",
    "TEST_DATA_FILE = './data/test_data.csv'\n",
    "test_data.to_csv(TEST_DATA_FILE, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push data to S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define S3 Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment metadata would be published at - s3://snowflake-getting-started/iris/experiments\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = 'snowflake-getting-started'\n",
    "BASE_PREFIX = 'iris'\n",
    "\n",
    "INPUT_DATA_PREFIX = BASE_PREFIX+'/data/input'\n",
    "TRAIN_DATA_PREFIX = BASE_PREFIX+'/data/input/train'\n",
    "TEST_DATA_PREFIX = BASE_PREFIX+'/data/input/test'\n",
    "\n",
    "EXPERIMENTS_OUTPUT_LOC = 's3://'+BUCKET_NAME+'/'+BASE_PREFIX+'/experiments'\n",
    "#DEBUGGING_OUTPUT_LOC = 's3://'+BUCKET_NAME+'/'+BASE_PREFIX+'/output/debugging'\n",
    "#MODELS_OUTPUT_LOC = 's3://'+BUCKET_NAME+'/output/models'\n",
    "\n",
    "print ('Experiment metadata would be published at -',EXPERIMENTS_OUTPUT_LOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading train data to s3\n",
      "Input data uploaded to - s3://snowflake-getting-started/iris/data/input/iris.csv\n"
     ]
    }
   ],
   "source": [
    "print ('Uploading train data to s3')\n",
    "\n",
    "s3_input_data_path = session.upload_data(path=DATA_FILE, \n",
    "                           bucket=BUCKET_NAME, \n",
    "                           key_prefix=INPUT_DATA_PREFIX)\n",
    "\n",
    "print ('Input data uploaded to -', s3_input_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing tasks\n",
    "\n",
    "    This is where we would do data pre-processing and convert intput data into some features. These features would then be uploaded to S3 and would be\n",
    "    used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Tracker for Pre-Processing\n",
    "\n",
    "    This is where we create a tracker for pre-processing job and add to it the following:\n",
    "    1 - Input data location (S3)\n",
    "    2 - Output data / Features Location (S3)\n",
    "    3 - Significant parameters from pre-processing.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "with Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n",
    "    tracker.log_parameters({\n",
    "        \"pre_processing_param\": 'pre_processing_param_value'\n",
    "    })\n",
    "    # we can log the s3 uri to the dataset we just uploaded\n",
    "    tracker.log_input(name=\"iris-dataset\", media_type=\"s3/uri\", value=s3_input_data_path)\n",
    "    tracker.log_output(name=\"iris-dataset\", media_type=\"s3/uri\", value=s3_input_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Setup an Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment debugging data available at - s3://snowflake-getting-started/iris/experiments/experiment-iris-classification-model-1595794471/debugging\n",
      "Experiment trained moddels available at - s3://snowflake-getting-started/iris/experiments/experiment-iris-classification-model-1595794471/trained_models\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "import time\n",
    "\n",
    "EXPERIMENT_NAME=f\"experiment-iris-classification-model-{int(time.time())}\"\n",
    "\n",
    "iris_experiment = Experiment.create(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    description=\"Classification of iris flowers\", \n",
    "    sagemaker_boto_client=sm)\n",
    "\n",
    "EXP_DEBUGGING_OUTPUTS=EXPERIMENTS_OUTPUT_LOC+'/'+EXPERIMENT_NAME+'/debugging'\n",
    "EXP_TRAINED_MODELS=EXPERIMENTS_OUTPUT_LOC+'/'+EXPERIMENT_NAME+'/trained_models'\n",
    "BASE_JOB_NAME=BASE_PREFIX+'/experiments'+EXPERIMENT_NAME+'/code'\n",
    "\n",
    "print ('Experiment debugging data available at -',EXP_DEBUGGING_OUTPUTS)\n",
    "print ('Experiment trained moddels available at -',EXP_TRAINED_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Track Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create a Trial for each training run to track the it's inputs, parameters, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n",
      "WARNING:sagemaker:This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig, CollectionConfig\n",
    "\n",
    "# we are taking the trial component which was created earlir for preprocessing. since for different training trails\n",
    "# our pre-processing trial is the same hence we just attach that preprocessing component to this trial.\n",
    "preprocessing_trial_component = tracker.trial_component\n",
    "\n",
    "save_interval ='1'\n",
    "\n",
    "for i, num_max_iter in enumerate([5,10]):\n",
    "    \n",
    "    # create trial\n",
    "    trial_name = f\"trial-iris-classification-model-{num_max_iter}-max-iter-{int(time.time())}\"\n",
    "    \n",
    "    iris_trial = Trial.create(\n",
    "        trial_name=trial_name, \n",
    "        experiment_name=iris_experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm,\n",
    "    )\n",
    "    \n",
    "    # associate the proprocessing trial component with the current trial\n",
    "    iris_trial.add_trial_component(preprocessing_trial_component)\n",
    "    \n",
    "    executor = SKLearn(entry_point='train.py',\n",
    "                      train_instance_type='ml.c4.xlarge',\n",
    "                      sagemaker_session = session,\n",
    "                      role = role,\n",
    "                      hyperparameters = {\n",
    "                          'max_iter':num_max_iter,\n",
    "                          'class_weight':'balanced'\n",
    "                      },\n",
    "                      input_mode='File',\n",
    "                      base_job_name=BASE_JOB_NAME,\n",
    "                      metric_definitions=[\n",
    "                        {'Name':'test:f1-score', 'Regex':'Test F1-Score: (.*)'},\n",
    "                        {'Name':'test:accuracy', 'Regex':'Test Accuracy: (.*)'}\n",
    "                      ],\n",
    "                      enable_sagemaker_metrics=True,\n",
    "                      debugger_hook_config=DebuggerHookConfig(\n",
    "                                  s3_output_path=EXP_DEBUGGING_OUTPUTS, \n",
    "                                  # Required - See https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md#built-in-collections for supported collections\n",
    "                                  collection_configs=[ \n",
    "                                      CollectionConfig( name=\"test-f1-score-collection\", \n",
    "                                                        parameters={\n",
    "                                                            'include_regex': 'Test F1-Score: (.*)',\n",
    "                                                            \"save_interval\": save_interval \n",
    "                                                        } \n",
    "                                                      ), \n",
    "                                      CollectionConfig( name=\"test-accuracy-collection\", \n",
    "                                                        parameters={\n",
    "                                                            'include_regex': 'Test Accuracy: (.*)',\n",
    "                                                            \"save_interval\": save_interval \n",
    "                                                        } \n",
    "                                                      ), \n",
    "                                      #CollectionConfig( name=\"feature_importance\", parameters={ \"save_interval\": save_interval } ), \n",
    "                                  ], \n",
    "                                ),\n",
    "                       # Configure debugger rule\n",
    "                       rules=[\n",
    "                            Rule.sagemaker(                                      \n",
    "                                rule_configs.loss_not_decreasing(),                  \n",
    "                                rule_parameters={\n",
    "                                    \"collection_names\": \"metrics\"\n",
    "                                },\n",
    "                            ),\n",
    "                        ],                     \n",
    "                      output_path = EXP_TRAINED_MODELS\n",
    "                )\n",
    "    \n",
    "    iris_training_job_name = \"training-job-iris-classification-model-{}\".format(int(time.time()))\n",
    "    executor.fit(\n",
    "        inputs={'training': s3_input_data_path},\n",
    "        job_name=iris_training_job_name,\n",
    "        experiment_config={\n",
    "            \"TrialName\": iris_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        },\n",
    "        logs=True,\n",
    "        wait=True\n",
    "    )\n",
    "    \n",
    "    # give it a while before dispatching the next training job\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the model training runs for an experiment\n",
    "\n",
    "Now we will use the analytics capabilities of Python SDK to query and compare the training runs for identifying the best model produced by our experiment. You can retrieve trial components by using a search expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Simple Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\":[\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>test:f1-score - Min</th>\n",
       "      <th>test:f1-score - Max</th>\n",
       "      <th>test:f1-score - Avg</th>\n",
       "      <th>test:f1-score - StdDev</th>\n",
       "      <th>test:f1-score - Last</th>\n",
       "      <th>test:f1-score - Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training-job-iris-classification-model-1595793...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:eu-west-1:951135073253:train...</td>\n",
       "      <td>\"balanced\"</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training-job-iris-classification-model-1595794...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:eu-west-1:951135073253:train...</td>\n",
       "      <td>\"balanced\"</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName DisplayName  \\\n",
       "0  training-job-iris-classification-model-1595793...    Training   \n",
       "1  training-job-iris-classification-model-1595794...    Training   \n",
       "\n",
       "                                           SourceArn class_weight  max_iter  \\\n",
       "0  arn:aws:sagemaker:eu-west-1:951135073253:train...   \"balanced\"       5.0   \n",
       "1  arn:aws:sagemaker:eu-west-1:951135073253:train...   \"balanced\"      10.0   \n",
       "\n",
       "   test:f1-score - Min  test:f1-score - Max  test:f1-score - Avg  \\\n",
       "0             1.000000             1.000000             1.000000   \n",
       "1             0.947368             0.947368             0.947368   \n",
       "\n",
       "   test:f1-score - StdDev  test:f1-score - Last  test:f1-score - Count  \n",
       "0                     0.0              1.000000                      1  \n",
       "1                     0.0              0.947368                      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.session import Session\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(boto3.Session(), sm), \n",
    "    experiment_name=iris_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.test:f1-score.max\",\n",
    "    metric_names=['test:f1-score'],\n",
    "    sort_order=\"Descending\",    \n",
    "    #metric_names=['test:f1-score'],\n",
    "    parameter_names=['max_iter', 'class_weight']\n",
    ")\n",
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>SageMaker.VolumeSizeInGB</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>sagemaker_container_log_level</th>\n",
       "      <th>...</th>\n",
       "      <th>test:f1-score - Avg</th>\n",
       "      <th>test:f1-score - StdDev</th>\n",
       "      <th>test:f1-score - Last</th>\n",
       "      <th>test:f1-score - Count</th>\n",
       "      <th>test:accuracy - Min</th>\n",
       "      <th>test:accuracy - Max</th>\n",
       "      <th>test:accuracy - Avg</th>\n",
       "      <th>test:accuracy - StdDev</th>\n",
       "      <th>test:accuracy - Last</th>\n",
       "      <th>test:accuracy - Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris-training-job-1595707533-aws-training-job</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:eu-west-1:951135073253:train...</td>\n",
       "      <td>141502667606.dkr.ecr.eu-west-1.amazonaws.com/s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.c4.xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>\"balanced\"</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              TrialComponentName DisplayName  \\\n",
       "0  iris-training-job-1595707533-aws-training-job    Training   \n",
       "\n",
       "                                           SourceArn  \\\n",
       "0  arn:aws:sagemaker:eu-west-1:951135073253:train...   \n",
       "\n",
       "                                  SageMaker.ImageUri  SageMaker.InstanceCount  \\\n",
       "0  141502667606.dkr.ecr.eu-west-1.amazonaws.com/s...                      1.0   \n",
       "\n",
       "  SageMaker.InstanceType  SageMaker.VolumeSizeInGB class_weight  max_iter  \\\n",
       "0           ml.c4.xlarge                      30.0   \"balanced\"      20.0   \n",
       "\n",
       "   sagemaker_container_log_level  ... test:f1-score - Avg  \\\n",
       "0                           20.0  ...            0.947368   \n",
       "\n",
       "  test:f1-score - StdDev test:f1-score - Last test:f1-score - Count  \\\n",
       "0                    0.0             0.947368                     1   \n",
       "\n",
       "  test:accuracy - Min  test:accuracy - Max  test:accuracy - Avg  \\\n",
       "0            0.947368             0.947368             0.947368   \n",
       "\n",
       "   test:accuracy - StdDev  test:accuracy - Last  test:accuracy - Count  \n",
       "0                     0.0              0.947368                      1  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(boto3.Session(), sm), \n",
    "    search_expression={\n",
    "        \"Filters\":[{\n",
    "            \"Name\": \"Parents.TrialName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": 'iris-training-job-20-max-iter-1595707533'\n",
    "        },\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }]\n",
    "    },\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Ascending\",\n",
    ")\n",
    "\n",
    "lineage_table.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Debugging Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smdebug\n",
    "from smdebug.trials import create_trial\n",
    "\n",
    "trial = create_trial(EXP_DEBUGGING_OUTPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "def get_data(trial, tname):\n",
    "    \"\"\"\n",
    "    For the given tensor name, walks though all the iterations\n",
    "    for which you have data and fetches the values.\n",
    "    Returns the set of steps and the values.\n",
    "    \"\"\"\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps()\n",
    "    vals = [tensor.value(s) for s in steps]\n",
    "    return steps, vals\n",
    "\n",
    "def plot_collection(trial, collection_name, regex='.*', figsize=(8, 6)):\n",
    "    \"\"\"\n",
    "    Takes a `trial` and a collection name, and \n",
    "    plots all tensors that match the given regex.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.despine()\n",
    "\n",
    "    tensors = trial.collection(collection_name).tensor_names\n",
    "\n",
    "    for tensor_name in sorted(tensors):\n",
    "        if re.match(regex, tensor_name):\n",
    "            steps, data = get_data(trial, tensor_name)\n",
    "            ax.plot(steps, data, label=tensor_name)\n",
    "\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_collection(trial, \"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(trial, importance_type=\"weight\"):\n",
    "    SUPPORTED_IMPORTANCE_TYPES = [\"weight\", \"gain\", \"cover\", \"total_gain\", \"total_cover\"]\n",
    "    if importance_type not in SUPPORTED_IMPORTANCE_TYPES:\n",
    "        raise ValueError(f\"{importance_type} is not one of the supported importance types.\")\n",
    "    plot_collection(\n",
    "        trial,\n",
    "        \"feature_importance\",\n",
    "        regex=f\"feature_importance/{importance_type}/.*\")\n",
    "    \n",
    " plot_feature_importance(trial)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - Real Time Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy Model to an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = executor.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "print('\\nModel Deployed!')\n",
    "\n",
    "print (predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realtime Inference\n",
    "\n",
    "    Lookup the predictor via the endpoint name & call predict on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(DATA_FILE,engine='python')\n",
    "X = data.iloc[:,1:5]\n",
    "y = data.iloc[:,5]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y)\n",
    "pred_y = predictor.predict(test_x)\n",
    "print (pred_y)\n",
    "print (test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
